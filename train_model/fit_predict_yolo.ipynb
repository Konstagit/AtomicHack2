{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb54ae9a-94e7-4b39-bf6b-c8b5f13c6778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T14:44:56.403533Z",
     "iopub.status.busy": "2024-06-15T14:44:56.402614Z",
     "iopub.status.idle": "2024-06-15T14:44:56.423313Z",
     "shell.execute_reply": "2024-06-15T14:44:56.422600Z",
     "shell.execute_reply.started": "2024-06-15T14:44:56.403477Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb7812f-e457-4251-a060-20d606055554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T12:36:18.538735Z",
     "iopub.status.busy": "2024-06-15T12:36:18.537457Z",
     "iopub.status.idle": "2024-06-15T12:36:18.552791Z",
     "shell.execute_reply": "2024-06-15T12:36:18.551993Z",
     "shell.execute_reply.started": "2024-06-15T12:36:18.538682Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_class_names(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        class_names = [line.strip() for line in file.readlines()]\n",
    "    return class_names\n",
    "\n",
    "def load_image(image_path):\n",
    "    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def load_labels(label_path):\n",
    "    with open(label_path, 'r') as file:\n",
    "        labels = [line.strip().split() for line in file.readlines()]\n",
    "    return labels\n",
    "\n",
    "def plot_image_with_labels(image, labels, class_names, image_id):\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'Image ID: {image_id}')\n",
    "    height, width, _ = image.shape\n",
    "    for label in labels:\n",
    "        class_id, x_center, y_center, bbox_width, bbox_height = map(float, label)\n",
    "        x_center *= width\n",
    "        y_center *= height\n",
    "        bbox_width *= width\n",
    "        bbox_height *= height\n",
    "        x_min = x_center - bbox_width / 2\n",
    "        y_min = y_center - bbox_height / 2\n",
    "        rect = plt.Rectangle((x_min, y_min), bbox_width, bbox_height, edgecolor='r', facecolor='none')\n",
    "        plt.gca().add_patch(rect)\n",
    "        \n",
    "        # Добавление текста с именем класса\n",
    "        class_name = class_names[int(class_id)]\n",
    "        # plt.text(x_min, y_min - 10, class_name, color='red', fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec2f9532-4417-4490-8ebc-f7fbc33d6342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T09:47:19.483445Z",
     "iopub.status.busy": "2024-06-15T09:47:19.481946Z",
     "iopub.status.idle": "2024-06-15T09:47:19.499810Z",
     "shell.execute_reply": "2024-06-15T09:47:19.498760Z",
     "shell.execute_reply.started": "2024-06-15T09:47:19.483388Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inferance(yolo, image_path, label_path):\n",
    "    img = load_image(image_path)\n",
    "    labels = load_labels(label_path)\n",
    "    pred = yolo(img, conf=0.5, device='cuda', show=False, save=True)\n",
    "    pred_boxes = pred[0].boxes.xywhn.cpu().numpy() \n",
    "    pred_cls = pred[0].boxes.cls.cpu().numpy().reshape(-1, 1)\n",
    "    pred_labels = np.hstack([pred_cls, pred_boxes])\n",
    "    \n",
    "    plot_image_with_labels(img, labels, pred_boxes, image_id='True')\n",
    "    plot_image_with_labels(img, pred_labels, pred_boxes, image_id='Predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e10eae2c-bd0f-431e-800f-f54a38a27aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T12:36:33.232458Z",
     "iopub.status.busy": "2024-06-15T12:36:33.231266Z",
     "iopub.status.idle": "2024-06-15T12:36:33.244720Z",
     "shell.execute_reply": "2024-06-15T12:36:33.243846Z",
     "shell.execute_reply.started": "2024-06-15T12:36:33.232413Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_path = '/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/val/images/1 (11).jpg'\n",
    "label_path = '/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/val/labels/1 (11).txt'\n",
    "\n",
    "# inferance(yolo, image_path, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3212e88f-1510-475a-9b69-45e728996f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T12:37:44.948849Z",
     "iopub.status.busy": "2024-06-15T12:37:44.947589Z",
     "iopub.status.idle": "2024-06-15T12:37:44.973763Z",
     "shell.execute_reply": "2024-06-15T12:37:44.972961Z",
     "shell.execute_reply.started": "2024-06-15T12:37:44.948801Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2'], dtype='<U8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(load_labels('/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/test/labels/9 (73).txt'))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6e5e0d48-f237-47fe-b140-89eb1e2dfae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T16:14:44.433837Z",
     "iopub.status.busy": "2024-06-15T16:14:44.432448Z",
     "iopub.status.idle": "2024-06-15T16:14:44.450124Z",
     "shell.execute_reply": "2024-06-15T16:14:44.449387Z",
     "shell.execute_reply.started": "2024-06-15T16:14:44.433778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "\n",
    "def load_labels(label_path):\n",
    "    with open(label_path, 'r') as file:\n",
    "        labels = [line.strip().split() for line in file.readlines()]\n",
    "    return np.array(labels)\n",
    "\n",
    "class CustomData(Dataset):\n",
    "    def __init__(self, image_dir, bbox_dir, img_size, labels_dict, transform=None):\n",
    "        super(CustomData).__init__()\n",
    "        self.image_dir = image_dir\n",
    "        self.bbox_dir = bbox_dir\n",
    "        self.img_size = img_size\n",
    "        self.labels_dict = labels_dict\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(self.image_dir)\n",
    "        self.bboxes = os.listdir(self.bbox_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bbox_dir)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.images[index]\n",
    "        bbox_name = self.bboxes[index]\n",
    "        image_path = rf'{self.image_dir}/{image_name}'\n",
    "        bbox_path = rf'{self.bbox_dir}/{bbox_name}'\n",
    "        print(image_path)\n",
    "        # image = cv2.imread(image_path)\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB), (640, 640))\n",
    "        labels_bboxes = load_labels(bbox_path)\n",
    "        print(labels_bboxes.shape)\n",
    "        if labels_bboxes is None:\n",
    "            return image, []\n",
    "\n",
    "        if len(labels_bboxes)==0:\n",
    "            return image, []\n",
    "\n",
    "        # print(labels_bboxes)\n",
    "        labels = labels_bboxes[:, 0].astype(np.int16)\n",
    "        bboxes = labels_bboxes[:, 1:].astype(np.float16)\n",
    "        w, h, _ = image.shape\n",
    "        \n",
    "        \n",
    "        # # shape=(1, 4)\n",
    "        # bboxes[:, 0] = bboxes[:, 0]*w\n",
    "        # bboxes[:, 2] = bboxes[:, 2]*w\n",
    "        # bboxes[:, 1] = bboxes[:, 1]*h\n",
    "        # bboxes[:, 3] = bboxes[:, 3]*h\n",
    "        \n",
    "\n",
    "        # bboxes = torch.tensor(bboxes, dtype=torch.int16)\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, bboxes=bboxes)\n",
    "            image = transformed['image']\n",
    "            bboxes = transformed['bboxes']\n",
    "        \n",
    "        \n",
    "        ########################################################\n",
    "\n",
    "        area = (bboxes[:, 3] - bboxes[:, 1]) * (bboxes[:, 2] - bboxes[:, 0])\n",
    "        area = torch.tensor(area, dtype=torch.int16)\n",
    "        # labels = [self.labels_dict[label] for label in bboxes[:, 4]]\n",
    "        labels = torch.tensor(labels, dtype=torch.int16)\n",
    "        \n",
    "        # labels = None\n",
    "        target = dict()\n",
    "        target['boxes'] = bboxes\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = torch.tensor([index], dtype=torch.int16)\n",
    "        target['area'] = area\n",
    "\n",
    "        ########################################################\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "baf02b3f-c970-494a-90b3-e278c4032ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T16:24:06.000371Z",
     "iopub.status.busy": "2024-06-15T16:24:05.998986Z",
     "iopub.status.idle": "2024-06-15T16:24:06.011474Z",
     "shell.execute_reply": "2024-06-15T16:24:06.010647Z",
     "shell.execute_reply.started": "2024-06-15T16:24:06.000312Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_train_transforms():\n",
    "#     return A.Compose([\n",
    "#         A.Resize(640, 640),\n",
    "#         A.SomeOf([\n",
    "#             A.Blur(p=1, blur_limit=3),\n",
    "#             A.Flip(p=1, always_apply=True),\n",
    "#             A.GaussNoise(p=1, always_apply=True),\n",
    "#             A.GridDistortion(p=1, always_apply=True),\n",
    "#             A.Rotate((-45, 45), p=1, always_apply=True),\n",
    "#             A.Transpose(p=1, always_apply=True),\n",
    "#             A.RandomBrightnessContrast((-0.1, 0.1), (-0.1, 0.1), p=1, always_apply=True)\n",
    "#         ], p=0.9, n=1),\n",
    "#         ToTensorV2()\n",
    "#     ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "# class CustomData(Dataset):\n",
    "#     def __init__(self, image_dir, bbox_dir, img_size, labels_dict, transform=None):\n",
    "#         super(CustomData).__init__()\n",
    "#         self.image_dir = image_dir\n",
    "#         self.bbox_dir = bbox_dir\n",
    "#         self.img_size = img_size\n",
    "#         self.labels_dict = labels_dict\n",
    "#         self.transform = transform\n",
    "#         self.images = os.listdir(self.image_dir)\n",
    "#         self.bboxes = os.listdir(self.bbox_dir)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.bboxes)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         image_name = self.images[index]\n",
    "#         bbox_name = self.bboxes[index]\n",
    "#         image_path = os.path.join(self.image_dir, image_name)\n",
    "#         bbox_path = os.path.join(self.bbox_dir, bbox_name)\n",
    "#         image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "#         labels_bboxes = load_labels(bbox_path)\n",
    "\n",
    "#         if labels_bboxes is None or len(labels_bboxes) == 0:\n",
    "#             return image, []\n",
    "\n",
    "#         labels = labels_bboxes[:, 0].astype(np.int16)\n",
    "#         bboxes = labels_bboxes[:, 1:].astype(np.float32)\n",
    "\n",
    "#         if self.transform:\n",
    "#             transformed = self.transform(image=image, bboxes=bboxes, labels=labels)\n",
    "#             image = transformed['image']\n",
    "#             bboxes = transformed['bboxes']\n",
    "#             labels = transformed['labels']\n",
    "\n",
    "#         area = (bboxes[:, 3] - bboxes[:, 1]) * (bboxes[:, 2] - bboxes[:, 0])\n",
    "#         area = torch.tensor(area, dtype=torch.float32)\n",
    "#         labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "#         target = dict()\n",
    "#         target['boxes'] = torch.tensor(bboxes, dtype=torch.float32)\n",
    "#         target['labels'] = labels\n",
    "#         target['image_id'] = torch.tensor([index], dtype=torch.int64)\n",
    "#         target['area'] = area\n",
    "\n",
    "#         return image, target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: len(x[1]) > 0, batch))\n",
    "    if not batch:\n",
    "        return torch.empty(0), torch.empty(0)\n",
    "    images, targets = zip(*batch)\n",
    "    images = torch.stack(images)\n",
    "    return images, targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f5364b34-3589-4738-b258-141c0c7eeaff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T16:24:06.196438Z",
     "iopub.status.busy": "2024-06-15T16:24:06.195083Z",
     "iopub.status.idle": "2024-06-15T16:24:06.212037Z",
     "shell.execute_reply": "2024-06-15T16:24:06.211261Z",
     "shell.execute_reply.started": "2024-06-15T16:24:06.196393Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN_ResNet50_FPN_V2_Weights, FasterRCNN_MobileNet_V3_Large_FPN_Weights\n",
    "import torch\n",
    "\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def get_model(num_classes = 6): # 4 = 3 + 1, учитываем еще фон\n",
    "    # box_detections_per_img=50\n",
    "    model = fasterrcnn_resnet50_fpn_v2(weights=FasterRCNN_ResNet50_FPN_V2_Weights.COCO_V1)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes).to(DEVICE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "903c4a30-8bb7-41db-a1fb-9662b7a915a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T16:24:06.697992Z",
     "iopub.status.busy": "2024-06-15T16:24:06.696809Z",
     "iopub.status.idle": "2024-06-15T16:24:06.727312Z",
     "shell.execute_reply": "2024-06-15T16:24:06.726456Z",
     "shell.execute_reply.started": "2024-06-15T16:24:06.697943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import clearml\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "\n",
    "def train(train_loader, val_loader, epochs):\n",
    "    model = get_model(num_classes=6)\n",
    "    params = [param for param in model.parameters() if param.requires_grad]\n",
    "    optimizer = optim.SGD(params,  lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "    \n",
    "    total_train_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch: {epoch + 1}')\n",
    "        train_loss = []\n",
    "        model.train()\n",
    "        for images, targets in train_loader:\n",
    "            images = list(torch.tensor(image, dtype=torch.float32).to(device) for image in images)\n",
    "            targets = [{k: torch.tensor(v, dtype=torch.int32).to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            train_loss.append(losses.item())\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_train_loss = np.mean(train_loss)\n",
    "        total_train_loss.append(epoch_train_loss)\n",
    "        print(f'Epoch train loss is: {epoch_train_loss}')\n",
    "\n",
    "    return model, total_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8c7063b7-7784-4272-b5ea-ef1544a68ced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T16:24:06.951789Z",
     "iopub.status.busy": "2024-06-15T16:24:06.950817Z",
     "iopub.status.idle": "2024-06-15T16:24:06.963775Z",
     "shell.execute_reply": "2024-06-15T16:24:06.962952Z",
     "shell.execute_reply.started": "2024-06-15T16:24:06.951746Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                A.SomeOf([\n",
    "                    A.Blur(p=1, blur_limit=3),\n",
    "                    A.Flip(p=1, ),\n",
    "                    A.GaussNoise(p=1),\n",
    "                    A.Transpose(p=1),\n",
    "                    \n",
    "                    # A.GridDistortion(p=1),\n",
    "                    # A.Rotate((-45, 45), p=1, ),\n",
    "                    # A.MedianBlur(p=1),\n",
    "                    # A.CLAHE(p=1),\n",
    "                    # A.RandomBrightnessContrast(p=1),\n",
    "                    # A.RandomGamma(p=1),\n",
    "                ], p=0.9, n=1),\n",
    "                A.Resize(640, 640),\n",
    "                A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "val_transform = A.Compose([\n",
    "        A.Resize(640, 640),\n",
    "        ToTensorV2()\n",
    "])\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "bae6e211-18c4-4702-b4f7-fbe2c9945cac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T16:24:07.208223Z",
     "iopub.status.busy": "2024-06-15T16:24:07.207038Z",
     "iopub.status.idle": "2024-06-15T16:24:07.225035Z",
     "shell.execute_reply": "2024-06-15T16:24:07.224303Z",
     "shell.execute_reply.started": "2024-06-15T16:24:07.208150Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# dataset = CustomData(image_dir, bbox_dir, img_size=640, labels_dict=labels_dict, transform=get_train_transforms())\n",
    "# dataloader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_dataset = CustomData(image_dir='/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images', \n",
    "                              bbox_dir='/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/labels',\n",
    "                              img_size=(640, 640), \n",
    "                              labels_dict='', \n",
    "                              transform=None)\n",
    "\n",
    "val_dataset = CustomData(image_dir='/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/val/images', \n",
    "                              bbox_dir='/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/val/labels',\n",
    "                              img_size=(640, 640), \n",
    "                              labels_dict='', \n",
    "                              transform=None)\n",
    "# test_dataset = CustomData(image_dir, bbox_dir, img_size, labels_dict, transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6336011",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, total_train_loss = train(train_loader, val_loader, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
